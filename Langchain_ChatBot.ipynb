{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82b07385-80fa-4d65-914e-a0d686d6107e",
   "metadata": {},
   "source": [
    "# 构建一个聊天机器人"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87982100-258e-4538-b52c-3b5efef06b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2ee51e5-7fc5-4817-9c2b-44879866d0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Bob! 👋 Nice to meet you! How can I help you today? 😊\n"
     ]
    }
   ],
   "source": [
    "chat = ChatOpenAI(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0.3,\n",
    "    max_tokens=200,\n",
    "    api_key='sk-6a82d1572f264b75952c7db2c081ef4c', # Deepseek api key\n",
    "    base_url=\"https://api.deepseek.com/v1\"\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(content=\"Hi! I'm Bob\"),\n",
    "]\n",
    "\n",
    "response = chat.invoke(messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf142d2-e7e2-44d6-9c4d-a88f16f23863",
   "metadata": {},
   "source": [
    "模型本身没有任何状态概念。例如，如果您问一个后续问题："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ec8e948-b54e-4feb-8d18-3a066e4e9181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don’t have access to personal information about you unless you share it with me. If you’d like, you can tell me your name, and I’ll happily use it in our conversation! 😊\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    HumanMessage(content=\"What's my name?\"),\n",
    "]\n",
    "response = chat.invoke(messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da9ebe9-ebfa-461e-8cb5-8035764b2fbc",
   "metadata": {},
   "source": [
    "我们可以看到它没有将之前的对话轮次作为上下文，因此无法回答问题。\n",
    "\n",
    "若加上之前的聊天记录："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "062073bf-bb21-4512-ada2-113f99245243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Bob! You mentioned it at the beginning of our conversation: \"Hello Bob!\"  \n",
      "\n",
      "Is there anything else you'd like help with? 😊\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    HumanMessage(content=\"What's my name?\"),\n",
    "    SystemMessage(content=\"Hello Bob! How can I assist you today?\"),\n",
    "    HumanMessage(content=\"What's my name?\"),\n",
    "]\n",
    "response = chat.invoke(messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb5a53c-4d37-4bc4-8035-f1a2264afdaa",
   "metadata": {},
   "source": [
    "现在我们可以看到我们得到了一个好的回应！\r\n",
    "\r\n",
    "这是支撑聊天机器人进行对话交互的基本理念。 那么我们如何最好地实现这一点呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61bffd4-41e1-4697-a444-92a9139154f9",
   "metadata": {},
   "source": [
    "### 消息历史"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebbd9aa-0c30-4f48-8617-ceddeb3a23a8",
   "metadata": {},
   "source": [
    "我们可以使用消息历史类来包装我们的模型，使其具有状态。 这将跟踪模型的输入和输出，并将其存储在某个数据存储中。 未来的交互将加载这些消息，并将其作为输入的一部分传递给链。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c17498-6f09-435e-b2dc-74a4c3242d24",
   "metadata": {},
   "source": [
    "1. 确保安装 langchain-community，因为将使用其中的集成来存储消息历史。(!pip install langchain_community)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bcbe6f-c3ca-4b65-a94d-252084920160",
   "metadata": {},
   "source": [
    "2. 之后，导入相关类并设置我们的链，该链包装模型并添加当前对话的消息历史。get_session_history作为传入的函数，预计接受一个session_id并返回一个消息历史对象。session_id用于区分不同对话，并作为配置的一部分在调用新链时传入。（一个对话一个链一个session_id）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6a8f19bc-55e7-4e79-9664-743ad4e454ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import (\n",
    "    BaseChatMessageHistory,\n",
    "    InMemoryChatMessageHistory,\n",
    ")\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(chat, get_session_history) # chat是之前调用的大模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2250271c-27d9-48ff-98c4-30e16cafe145",
   "metadata": {},
   "source": [
    "3. 创建一个config，用于配置一个session_id，让大模型知道要读取哪一段消息历史。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ece7632a-a69a-4728-85da-7a7091f89714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi Bob! 👋 Nice to meet you. How can I help you today? 😊'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"abc2\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi! I'm Bob\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4c4e3f5e-459d-4a6d-9275-7bed3416d50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is **Bob**—unless you’ve changed it in the last few seconds! 😄 What’s up, Bob? Anything fun or interesting on your mind?'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45412da-5462-479a-99d8-75a44b21f50e",
   "metadata": {},
   "source": [
    "如果我们更改配置以引用不同的 session_id，我们可以看到它开始新的对话。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bd98550d-5b97-41b6-9a8b-356ad6df5649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I don’t have access to personal information about you unless you share it with me. If you’d like, you can tell me your name, and I’ll be happy to use it in our conversation! 😊'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"abc3\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a68400-cbee-4677-bcb9-557b60c9a6f6",
   "metadata": {},
   "source": [
    "而且，我们始终可以回到原始对话（因为我们将其保存在数据库中）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "292b6049-ea30-4805-9ef6-21efceb14714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Still **Bob**! Unless you're secretly a undercover agent with a codename—then I might need a hint. 😉  \\n\\nWhat’s the plan today, Bob? Or should I call you *Agent B* now? 🕵️\\u200d♂️\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"abc2\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85faabb-7b49-49c2-a0a1-909d35d9c51f",
   "metadata": {},
   "source": [
    "现在，我们所做的只是为模型添加了一个简单的持久化层（将聊天机器人和用户的对话历史进行存储并保持的机制，使对话不会丢失）。我们可以通过添加提示词模板来使其变得更加复杂和个性化。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6eb973-1003-4d5a-bb4e-b4e6e3bf4ea5",
   "metadata": {},
   "source": [
    "### 提示词模板"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc51bfa-3fa3-40f0-ae4d-6ba5427e37a8",
   "metadata": {},
   "source": [
    "提示词模板帮助将原始用户信息转换为大型语言模型可以处理的格式。在这种情况下，原始用户输入只是一个消息，我们将其传递给大型语言模型。现在让我们使其变得更复杂一些。首先，让我们添加一个带有一些自定义指令的系统消息（但仍然将消息作为输入）。接下来，我们将添加除了消息之外的更多输入。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b90b115-f0d8-401c-a4f4-ac7179f8a4c6",
   "metadata": {},
   "source": [
    "1. 首先，让我们添加一个系统消息。为此，我们将创建一个 ChatPromptTemplate。我们将利用 MessagesPlaceholder 来传递所有消息。\n",
    "\n",
    "*chain = prompt | model*：通过 “|” 运算符将提示模板prompt与语言模型model串联成一个链chain。这意味着在调用chain时，会先将输入数据传入prompt进行处理（生成包含系统消息和具体对话消息的完整提示），再将处理结果传递给model进行推理，最终得到 AI 的回复。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f049d208-4354-4ea4-b36a-6e231650f02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"), # 表示后续会通过键为 “messages” 的参数传入具体消息\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0f0f70-a376-407e-950f-8e53270c5682",
   "metadata": {},
   "source": [
    "2. 传递一个包含 messages 键的字典，其中包含一系列消息，而不是传递消息列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "087927db-782a-4922-b1e8-79b2ae6cdc66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Bob! 👋 How's it going? What can I help you with today? 😊\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"messages\": [HumanMessage(content=\"hi! I'm bob\")]})\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d0aabe-8d0c-4f32-9dd2-542239b4574b",
   "metadata": {},
   "source": [
    "3. 现在，将其包装在消息历史对象中，与大模型对话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0e4d1f7c-be0e-41f0-9fde-cefa85caf864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Jim! How can I assist you today? Whether you have questions, need help with something, or just want to chat, I'm here for you. Let me know what's on your mind!\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)\n",
    "config = {\"configurable\" : {\"session_id\" : \"abc5\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content = \"I'm Jim\")],\n",
    "    config = config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c227de06-5c5d-4ea8-a13e-e6bd287d0147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is **Jim**! You mentioned it right at the beginning: *\"I\\'m Jim.\"*  \\n\\nLet me know if there\\'s anything else you\\'d like help with, Jim! 😊'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content = \"What's my name?\")],\n",
    "    config = config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852d7150-ff9a-47d7-b332-b6f554e1dd54",
   "metadata": {},
   "source": [
    "✳现在将系统提示改变的更复杂一点"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b912070-85bd-4ab6-997d-e4240abea121",
   "metadata": {},
   "source": [
    "1. 改变提示词，并在提示词中加入{language}变量，使得我们可以自定义变量值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7668221a-af09-4ac9-b8ba-56d10bc61eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1ffe69-df9d-4dd5-ba7c-f3be5bca5d5e",
   "metadata": {},
   "source": [
    "2. 包装在消息历史对象中。因为多了一个输入的键，需要明确指定哪一个键来保存聊天历史"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e9559d19-5740-4d44-a943-67399f67f597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¡Hola, Todd! ¿Cómo estás? 😊 ¿En qué puedo ayudarte hoy?  \\n\\n*(Translation: Hi, Todd! How are you? 😊 How can I help you today?)*  \\n\\nFeel free to ask me anything in Spanish or English—I’m happy to help!'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history, input_messages_key=\"messages\",)\n",
    "config = {\"configurable\": {\"session_id\": \"abc10\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"hi! I'm todd\")], \n",
    "        \"language\": \"Spanish\"\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abe21a5-b4d6-48d4-bf8a-14b9f2f22fdd",
   "metadata": {},
   "source": [
    "### 管理对话历史"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc01923f-208a-4d04-b89d-ef62d3575f94",
   "metadata": {},
   "source": [
    "构建聊天机器人时，一个重要的概念是如何管理对话历史。如果不加以管理，消息列表将无限增长，并可能溢出大型语言模型的上下文窗口。因此，添加一个限制您传入消息大小的步骤是很重要的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67304e4-5bc8-44ce-b0db-6077c620508e",
   "metadata": {},
   "source": [
    "❗重要的是，此管理对话历史的步骤，需要在提示模板之前，以及获取所有对话历史之后，再执行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3eb2b9-4c45-443f-b338-ca6d7a0f6cf0",
   "metadata": {},
   "source": [
    "因为deepseek中没有token计数的方法，所以我们先自定义一个方法，如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "70448bf6-b14b-42ee-921c-8d9ba2e93bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in c:\\users\\19546\\anaconda3\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\19546\\anaconda3\\lib\\site-packages (from tiktoken) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\19546\\anaconda3\\lib\\site-packages (from tiktoken) (2.32.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\19546\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\19546\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\19546\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\19546\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b42be319-f175-44af-a8fc-6fed77cadbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "# pip install tiktoken\n",
    "import tiktoken\n",
    "from langchain_core.messages import BaseMessage, ToolMessage\n",
    "\n",
    "\n",
    "def str_token_counter(text: str) -> int:\n",
    "    enc = tiktoken.get_encoding(\"o200k_base\")\n",
    "    return len(enc.encode(text))\n",
    "\n",
    "\n",
    "def tiktoken_counter(messages: List[BaseMessage]) -> int:\n",
    "    \"\"\"Approximately reproduce https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "\n",
    "    For simplicity only supports str Message.contents.\n",
    "    \"\"\"\n",
    "    num_tokens = 3  # every reply is primed with <|start|>assistant<|message|>\n",
    "    tokens_per_message = 3\n",
    "    tokens_per_name = 1\n",
    "    for msg in messages:\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            role = \"user\"\n",
    "        elif isinstance(msg, AIMessage):\n",
    "            role = \"assistant\"\n",
    "        elif isinstance(msg, ToolMessage):\n",
    "            role = \"tool\"\n",
    "        elif isinstance(msg, SystemMessage):\n",
    "            role = \"system\"\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported messages type {msg.__class__}\")\n",
    "        num_tokens += (\n",
    "            tokens_per_message\n",
    "            + str_token_counter(role)\n",
    "            + str_token_counter(msg.content)\n",
    "        )\n",
    "        if msg.name:\n",
    "            num_tokens += tokens_per_name + str_token_counter(msg.name)\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1999f3ae-d816-4d3e-bb79-f924e340989f",
   "metadata": {},
   "source": [
    "LangChain 提供了一些内置的助手来 管理消息列表。在这种情况下，我们将使用 trim_messages 助手来减少我们发送给模型的消息数量。修剪器允许我们指定希望保留的令牌数量，以及其他参数，例如是否希望始终保留系统消息以及是否允许部分消息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a54816ea-c2c6-44e1-a6c5-942ea8c1f1bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, trim_messages\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=65,       # 规定了修剪后消息的最大令牌数\n",
    "    strategy=\"last\",     # 表示保留最近的消息\n",
    "    token_counter=tiktoken_counter,  # 指定用所使用的语言模型来计算令牌数\n",
    "    include_system=True, # 确保系统消息始终被保留\n",
    "    allow_partial=False, # 表示不允许保留不完整的消息\n",
    "    start_on=\"human\",    # 指定从人类消息开始处理\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbf8a16-874c-4ac0-a0b2-0f99c834e6ba",
   "metadata": {},
   "source": [
    "现在如果我们尝试询问模型我们的名字，它将不知道，因为我们修剪了聊天历史的那部分:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "07f33888-323c-4d7f-a421-bd40daa4addc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I don’t have access to personal information, so I don’t know your name. But I’d be happy to call you whatever you like—just let me know! 😊'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\") | trimmer) # 作用是在链中添加一个处理步骤，对输入的消息列表进行修剪\n",
    "    | prompt\n",
    "    | chat\n",
    ")\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"what's my name?\")],\n",
    "        \"language\": \"English\",\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "eb5c0282-90ff-494f-bc6a-1b2120f613c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked, *\"whats 2 + 2\"*, and I answered *\"4\"*. Then you said *\"thanks\"*, and I replied *\"no problem!\"*. After that, you asked *\"having fun?\"*, and I said *\"yes!\"*.  \\n\\nNow you’re asking *\"what question did I ask?\"* — which is this very meta moment! 😄  \\n\\nLet me know what’s next!'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"what question did I ask?\")],\n",
    "        \"language\": \"English\",\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52548887-7245-40e8-8276-2a13d40553dc",
   "metadata": {},
   "source": [
    "现在，我们将修剪器包装在消息历史中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d54b96c2-ce54-49ce-b9e6-4b99950ba141",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\") | trimmer) # 作用是在链中添加一个处理步骤，对输入的消息列表进行修剪\n",
    "    | prompt\n",
    "    | chat\n",
    ")\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"session_id\": \"abc20\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "d3c001fa-91f0-4c1d-9481-a251b377f43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked, *\"whats 2 + 2\"*, and I answered *\"4\"*. Then you said *\"thanks\"*, and I replied *\"no problem!\"*. After that, you asked *\"having fun?\"*, and I said *\"yes!\"*.  \\n\\nNow you just asked: *\"what question did I ask?\"*  \\n\\nLet me know if you\\'d like to dive deeper into any of these! 😊'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"what question did I ask?\")],\n",
    "        \"language\": \"English\",\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55699d21-e8f0-4bd5-8c37-ee3bd750a82f",
   "metadata": {},
   "source": [
    "### 流式处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35eb7af-eef6-4484-b181-062a7a1a9299",
   "metadata": {},
   "source": [
    "大型语言模型有时可能需要一段时间才能响应，因此为了改善用户体验，大多数应用程序所做的一件事是随着每个令牌的生成流回。这样用户就可以看到进度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb6793b-58ac-4f75-a1ea-3d49e51d8220",
   "metadata": {},
   "source": [
    "所有链都暴露一个.stream方法，使用消息历史的链也不例外。我们可以简单地使用该方法获取流式响应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "5b5be597-26e5-4d84-89e9-cbae3f78a908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Hi| Todd|!| Here|'s| a| joke| for| you|:|  \n",
      "\n",
      "|**|Why| don|’|t| skeletons| fight| each| other|?|**|  \n",
      "|*|Because| they| don|’|t| have| the| guts|!|*|  \n",
      "\n",
      "|Hope| that| gives| you| a| chuckle|!| 😄| Got| any| favorite| joke| topics|?||"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"abc15\"}}\n",
    "for r in with_message_history.stream(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"hi! I'm todd. tell me a joke\")],\n",
    "        \"language\": \"English\",\n",
    "    },\n",
    "    config=config,\n",
    "):\n",
    "    print(r.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8856c15f-5317-4641-bfec-d8c66878b9fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "788c97bd-dd27-4d76-be5d-4a33eb7e17b4",
   "metadata": {},
   "source": [
    "### 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb34346-42ca-43fa-be83-0c6c69a2e184",
   "metadata": {},
   "source": [
    "* 想要对话带历史对话，封装入消息历史对象中，此时需要配置session_id，invoke函数中要传入config，指定调用哪一个对话历史。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bcaed0-6828-41dd-8afd-47363475e5be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
